# ğŸ¥ æœ¬åœ°è§†é¢‘å¤„ç†ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬åœ°è§†é¢‘å¤„ç†ç³»ç»Ÿæä¾›äº†ä¸ä¾èµ–VideoDBçš„å®Œæ•´è§†é¢‘å¤„ç†å’Œç´¢å¼•åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

- âœ… **è¯­éŸ³è½¬æ–‡å­—** - ä½¿ç”¨OpenAI Whisperæ¨¡å‹
- âœ… **åœºæ™¯æ£€æµ‹** - ä½¿ç”¨PySceneDetectè‡ªåŠ¨åˆ†å‰²è§†é¢‘åœºæ™¯
- âœ… **å¸§æå–** - ä½¿ç”¨OpenCVæå–å…³é”®å¸§
- âœ… **æœ¬åœ°å­˜å‚¨** - SQLiteæ•°æ®åº“ç®¡ç†è§†é¢‘ç´¢å¼•
- âœ… **æ–‡æœ¬æœç´¢** - åœ¨è½¬å½•æ–‡æœ¬ä¸­å¿«é€Ÿæœç´¢
- âœ… **å®Œå…¨æœ¬åœ°åŒ–** - æ•°æ®ä¸ç¦»å¼€æœ¬åœ°ç¯å¢ƒ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# åŸºæœ¬ä¾èµ–
pip install opencv-python whisper-openai scenedetect[opencv]

# éŸ³é¢‘å¤„ç†
pip install librosa soundfile

# è§†é¢‘å¤„ç†ï¼ˆéœ€è¦FFmpegï¼‰
pip install ffmpeg-python

# ç¡®ä¿å®‰è£…FFmpeg
# Windows: choco install ffmpeg
# macOS: brew install ffmpeg  
# Ubuntu: sudo apt install ffmpeg
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from director.tools.local_video_processor import LocalVideoProcessor

# åˆå§‹åŒ–å¤„ç†å™¨
processor = LocalVideoProcessor(storage_path="./my_videos")

# ä¸Šä¼ è§†é¢‘
result = processor.upload_video("path/to/video.mp4", "my_video_001")

# è½¬å½•è§†é¢‘
transcript = processor.transcribe_video("my_video_001")

# æ£€æµ‹åœºæ™¯
scenes = processor.detect_scenes("my_video_001")

# æœç´¢è½¬å½•
results = processor.search_transcript("my_video_001", "å…³é”®è¯")
```

### 3. ä½¿ç”¨Agentæ¥å£

```python
from director.agents.local_video_agent import LocalVideoAgent
from director.core.session import Session
from director.db.sqlite.db import SqliteDB

# åˆ›å»ºä¼šè¯
db = SqliteDB(":memory:")
session = Session(db=db)

# åˆ›å»ºAgent
agent = LocalVideoAgent(session=session)

# ä¸Šä¼ è§†é¢‘
response = agent.run(
    action="upload",
    video_path="/path/to/video.mp4",
    video_id="test_video"
)

# è½¬å½•è§†é¢‘
response = agent.run(
    action="transcribe", 
    video_id="test_video"
)

# æ£€æµ‹åœºæ™¯
response = agent.run(
    action="detect_scenes",
    video_id="test_video",
    threshold=25.0  # è°ƒæ•´æ•æ„Ÿåº¦
)

# æœç´¢è½¬å½•
response = agent.run(
    action="search",
    video_id="test_video", 
    query="é‡è¦å†…å®¹"
)
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
local_video_storage/
â”œâ”€â”€ videos/           # å­˜å‚¨è½¬æ¢åçš„è§†é¢‘æ–‡ä»¶
â”œâ”€â”€ frames/           # å­˜å‚¨æå–çš„å…³é”®å¸§
â”œâ”€â”€ transcripts/      # å­˜å‚¨å®Œæ•´è½¬å½•JSONæ–‡ä»¶
â”œâ”€â”€ scenes/           # å­˜å‚¨åœºæ™¯æ•°æ®
â””â”€â”€ video_index.db    # SQLiteæ•°æ®åº“
```

## ğŸ”§ é…ç½®é€‰é¡¹

### Whisperæ¨¡å‹é€‰æ‹©

```python
# å¯ç”¨æ¨¡å‹ï¼ˆæŒ‰å‡†ç¡®åº¦å’Œé€Ÿåº¦æ’åºï¼‰
models = ["tiny", "base", "small", "medium", "large"]

# åœ¨LocalVideoProcessorä¸­ä¿®æ”¹
self.whisper_model = whisper.load_model("medium")  # æ›´é«˜å‡†ç¡®åº¦
```

### åœºæ™¯æ£€æµ‹è°ƒä¼˜

```python
# æ£€æµ‹æ•æ„Ÿåº¦è°ƒæ•´
processor.detect_scenes(video_id, threshold=30.0)  # ä¸å¤ªæ•æ„Ÿ
processor.detect_scenes(video_id, threshold=20.0)  # æ›´æ•æ„Ÿ
```

### è¯­è¨€è®¾ç½®

```python
# åœ¨transcribe_videoä¸­ä¿®æ”¹è¯­è¨€
result = self.whisper_model.transcribe(
    audio_path, 
    language="en"  # è‹±æ–‡
    # language="zh"  # ä¸­æ–‡
    # language=None  # è‡ªåŠ¨æ£€æµ‹
)
```

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæ•™è‚²è§†é¢‘åˆ†æ

```python
# å¤„ç†åœ¨çº¿è¯¾ç¨‹è§†é¢‘
processor = LocalVideoProcessor("./course_videos")

# æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘
course_videos = ["lecture1.mp4", "lecture2.mp4", "lecture3.mp4"]

for i, video_path in enumerate(course_videos):
    video_id = f"lecture_{i+1}"
    
    # ä¸Šä¼ å’Œè½¬å½•
    processor.upload_video(video_path, video_id)
    processor.transcribe_video(video_id)
    processor.detect_scenes(video_id)
    
    # æœç´¢ç‰¹å®šä¸»é¢˜
    results = processor.search_transcript(video_id, "æœºå™¨å­¦ä¹ ")
    print(f"åœ¨ç¬¬{i+1}è®²ä¸­æ‰¾åˆ°{len(results)}ä¸ªç›¸å…³ç‰‡æ®µ")
```

### æ¡ˆä¾‹2ï¼šä¼šè®®å½•éŸ³åˆ†æ

```python
# å¤„ç†ä¼šè®®å½•éŸ³
processor = LocalVideoProcessor("./meeting_records")

# ä¸Šä¼ ä¼šè®®è§†é¢‘
processor.upload_video("meeting_2024_01_15.mp4", "meeting_20240115")

# è½¬å½•ä¼šè®®å†…å®¹
transcript = processor.transcribe_video("meeting_20240115")

# æœç´¢å…³é”®å†³ç­–ç‚¹
decisions = processor.search_transcript("meeting_20240115", "å†³å®š")
action_items = processor.search_transcript("meeting_20240115", "è¡ŒåŠ¨é¡¹")

print("ä¼šè®®å†³ç­–ç‚¹ï¼š")
for item in decisions:
    print(f"  {item['start_time']:.1f}s: {item['text']}")
```

### æ¡ˆä¾‹3ï¼šåª’ä½“å†…å®¹ç´¢å¼•

```python
# å¤„ç†åª’ä½“å†…å®¹
processor = LocalVideoProcessor("./media_library")

def process_media_file(file_path):
    video_id = Path(file_path).stem
    
    # å®Œæ•´å¤„ç†æµç¨‹
    upload_result = processor.upload_video(file_path, video_id)
    if upload_result["success"]:
        # è½¬å½•
        processor.transcribe_video(video_id)
        
        # åœºæ™¯æ£€æµ‹
        scenes = processor.detect_scenes(video_id, threshold=25.0)
        
        # è¿”å›å¤„ç†ç»“æœ
        return {
            "video_id": video_id,
            "duration": upload_result["video_info"]["duration"],
            "scenes_count": scenes["total_scenes"] if scenes["success"] else 0
        }

# æ‰¹é‡å¤„ç†
results = []
for video_file in Path("./raw_videos").glob("*.mp4"):
    result = process_media_file(str(video_file))
    results.append(result)

print(f"å¤„ç†äº†{len(results)}ä¸ªè§†é¢‘æ–‡ä»¶")
```

## ğŸ” é«˜çº§æœç´¢åŠŸèƒ½

### æ—¶é—´èŒƒå›´æœç´¢

```python
def search_in_timerange(processor, video_id, query, start_time, end_time):
    """åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æœç´¢"""
    all_results = processor.search_transcript(video_id, query)
    
    filtered_results = [
        r for r in all_results 
        if start_time <= r["start_time"] <= end_time
    ]
    
    return filtered_results

# åªåœ¨å‰5åˆ†é’Ÿæœç´¢
results = search_in_timerange(processor, "video_001", "ä»‹ç»", 0, 300)
```

### æ‰¹é‡æœç´¢

```python
def search_multiple_videos(processor, video_ids, query):
    """åœ¨å¤šä¸ªè§†é¢‘ä¸­æœç´¢"""
    all_results = {}
    
    for video_id in video_ids:
        results = processor.search_transcript(video_id, query)
        if results:
            all_results[video_id] = results
    
    return all_results

# åœ¨æ‰€æœ‰è§†é¢‘ä¸­æœç´¢å…³é”®è¯
results = search_multiple_videos(
    processor, 
    ["video_001", "video_002", "video_003"], 
    "é‡è¦ä¿¡æ¯"
)
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. FFmpegæœªå®‰è£…**
```bash
# é”™è¯¯ï¼šFileNotFoundError: [Errno 2] No such file or directory: 'ffmpeg'
# è§£å†³ï¼šå®‰è£…FFmpeg
pip install ffmpeg-python
# å¹¶ç¡®ä¿ç³»ç»ŸPATHä¸­æœ‰ffmpegå¯æ‰§è¡Œæ–‡ä»¶
```

**2. Whisperæ¨¡å‹ä¸‹è½½å¤±è´¥**
```python
# é”™è¯¯ï¼šURLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]>
# è§£å†³ï¼šæ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
import whisper
whisper.load_model("base", download_root="./models")
```

**3. OpenCVå®‰è£…é—®é¢˜**
```bash
# é”™è¯¯ï¼šImportError: No module named 'cv2'
# è§£å†³ï¼šé‡æ–°å®‰è£…OpenCV
pip uninstall opencv-python
pip install opencv-python==4.10.0.84
```

**4. å†…å­˜ä¸è¶³**
```python
# å¯¹äºå¤§è§†é¢‘æ–‡ä»¶ï¼Œå¯ä»¥è°ƒæ•´å¤„ç†å‚æ•°
processor = LocalVideoProcessor()
# ä½¿ç”¨æ›´å°çš„Whisperæ¨¡å‹
processor.whisper_model = whisper.load_model("tiny")
```

### æ€§èƒ½ä¼˜åŒ–

**1. é€‰æ‹©åˆé€‚çš„Whisperæ¨¡å‹**
- `tiny`: æœ€å¿«ï¼Œå‡†ç¡®åº¦è¾ƒä½
- `base`: å¹³è¡¡é€‰æ‹©
- `small`: è¾ƒå¥½å‡†ç¡®åº¦
- `medium`: é«˜å‡†ç¡®åº¦
- `large`: æœ€é«˜å‡†ç¡®åº¦ï¼Œæœ€æ…¢

**2. åœºæ™¯æ£€æµ‹ä¼˜åŒ–**
```python
# é™ä½é˜ˆå€¼å¢åŠ æ•æ„Ÿåº¦ï¼ˆæ›´å¤šåœºæ™¯ï¼‰
scenes = processor.detect_scenes(video_id, threshold=20.0)

# æé«˜é˜ˆå€¼å‡å°‘æ•æ„Ÿåº¦ï¼ˆæ›´å°‘åœºæ™¯ï¼‰
scenes = processor.detect_scenes(video_id, threshold=35.0)
```

**3. æ‰¹å¤„ç†ä¼˜åŒ–**
```python
# å¯¹äºå¤§é‡è§†é¢‘ï¼Œè€ƒè™‘å¹¶è¡Œå¤„ç†
from concurrent.futures import ThreadPoolExecutor

def process_video(video_path):
    # å¤„ç†å•ä¸ªè§†é¢‘çš„å‡½æ•°
    pass

with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(process_video, path) for path in video_paths]
    results = [future.result() for future in futures]
```

## ğŸ“Š ä¸VideoDBåŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | VideoDB | æœ¬åœ°å¤„ç†ç³»ç»Ÿ |
|------|---------|-------------|
| è§†é¢‘å­˜å‚¨ | âœ… äº‘ç«¯ | âœ… æœ¬åœ° |
| è¯­éŸ³è½¬æ–‡å­— | âœ… | âœ… (Whisper) |
| åœºæ™¯æ£€æµ‹ | âœ… | âœ… (PySceneDetect) |
| è¯­ä¹‰æœç´¢ | âœ… | âš ï¸ (å¯æ‰©å±•) |
| è§†é¢‘æµæ’­æ”¾ | âœ… | âŒ |
| APIè®¿é—® | âœ… | âœ… |
| æ•°æ®éšç§ | âš ï¸ äº‘ç«¯ | âœ… å®Œå…¨æœ¬åœ° |
| æˆæœ¬ | ğŸ’° æŒ‰ä½¿ç”¨ä»˜è´¹ | ğŸ’° ä¸€æ¬¡æ€§è®¾ç½® |
| æ‰©å±•æ€§ | âœ… æ— é™ | âš ï¸ ç¡¬ä»¶é™åˆ¶ |

## ğŸš€ æœªæ¥æ‰©å±•

å¯ä»¥è€ƒè™‘æ·»åŠ çš„åŠŸèƒ½ï¼š

1. **è¯­ä¹‰æœç´¢** - é›†æˆsentence-transformers
2. **äººè„¸è¯†åˆ«** - ä½¿ç”¨face_recognitionåº“
3. **ç‰©ä½“æ£€æµ‹** - é›†æˆYOLOæ¨¡å‹
4. **æƒ…æ„Ÿåˆ†æ** - åˆ†æè¯­éŸ³æƒ…æ„Ÿ
5. **è‡ªåŠ¨æ ‡ç­¾** - AIç”Ÿæˆè§†é¢‘æ ‡ç­¾
6. **è§†é¢‘å‹ç¼©** - è‡ªåŠ¨ä¼˜åŒ–å­˜å‚¨ç©ºé—´

è¿™ä¸ªæœ¬åœ°è§†é¢‘å¤„ç†ç³»ç»Ÿä¸ºä½ æä¾›äº†å®Œå…¨çš„æ•°æ®æ§åˆ¶æƒï¼ŒåŒæ—¶ä¿æŒäº†å¼ºå¤§çš„è§†é¢‘åˆ†æèƒ½åŠ›ï¼ 